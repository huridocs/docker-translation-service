version: '3.8'

services:
  ollama-translations:
    container_name: ollama-translations
    image: ollama/ollama:0.2.1
    network_mode: host
    volumes:
      - ./ollama/ollama:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
  worker_translations:
    container_name: worker_translations
    environment:
      LOGGING_LEVEL: "WARNING"
    init: true
    entrypoint: [ "python", "-m", "src.start_queue_processor" ]
    build:
      context: .
      dockerfile: Dockerfile
    network_mode: host